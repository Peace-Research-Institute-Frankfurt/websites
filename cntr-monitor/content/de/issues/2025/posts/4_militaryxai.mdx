---
order: 4
eyebrow: Künstliche Intelligenz
title: 'Kriegsführung im Prozessortakt: Der zunehmende Einsatz von KI beim Militär'
intro: 'Die Debatte über den militärischen Einsatz von KI hat sich intensiviert, zunächst im Hinblick auf (tödliche) autonome Waffensysteme. Autonome Waffensysteme wählen selbstständig Ziele aus, setzen Prioritäten und greifen sie an, was sie tödlich macht, wenn Menschen im Visier sind. Die Debatten über diese Waffensysteme, die um 2010 aufkamen, finden sich nun in der UN-Waffenkonvention und in der UN-Generalversammlung wieder. Allerdings haben die Kritiker\*innen der autonomen Waffen den Fokus der Debatte zu lange auf nur zwei kritische Elemente verengt: Zielwahl und Einsatz. Dies änderte sich erst kürzlich mit einer Debatte, die sich auf die breitere „Zuverlässigkeit“ militärischer KI und damit verbundene Versprechen oder nationale (militärische) KI-Strategien konzentrierte. Während sowohl der Umfang als auch die Fähigkeiten von KI im militärischen Kontext noch diskutiert werden, wird KI zunehmend auch in scheinbar unkritischen militärischen Bereichen eingesetzt. Während die Militärs dies als Gewinn an Effizienz und Anwendung in vermeintlich harmlosen Rollen und Funktionen feiern, wirft es ernste rüstungskontrollpolitische Fragen auf, insbesondere im Hinblick auf die Beschleunigung der Kriegsführung und der Erosion der menschlichen Kontrolle. Auch wenn man das Interesse der Staaten am Einsatz militärischer KI anerkennt, sollten die Debatten über die Auswirkungen extensiver KI-Nutzung auf die Stabilität und die Sicherheit intensiviert werden, wobei auch Fragen jenseits der ethischen oder rechtlichen Aspekte in den Blick genommen werden sollten.'
category: Fokus
tags:
-	Autonome Waffensysteme
-	Drohnen
-	Israel
-	LAWS
-	Maven
-	USA
authors:
  - n-schoernig25
---

<Leadin>Die in den</Leadin> späten 2000er Jahren begonnene Debatte über (tödliche) autonome Waffensysteme (Lethal Autonomous Weapon Systems, LAWS) entsprach nicht immer dem, was wir heute unter „KI“ verstehen. Damals hatte die öffentliche Wahrnehmung von KI mehr mit komplexen, deterministischen Algorithmen oder „Expertensystemen“ zu tun als mit modernem maschinellem Lernen oder tiefen neuronalen Netzen. In ähnlicher Weise konzentrierten sich die Debatten über KI in Waffensystemen auf nur zwei Elemente der „Wirkungskette“: die Auswahl des Ziels und den Einsatz – d. h. die Entscheidung zum Angriff.

Viele Kritiker\*innen waren empört über die Vorstellung, dass ein Algorithmus ohne menschliche Beteiligung über einen Angriff entscheiden und ihn auslösen sollte, und befürchteten Verstöße gegen das Völkerrecht und die Menschenwürde. Während solche Argumente selbst unter den Befürworter*innen umstritten bleiben,[^1] gab es zwar sicherheitspolitische Kritik, aber oft deutlich zurückhaltender als die rechtlich oder ethisch begründete Kritik.[^2] Die rechtlichen Bedenken konzentrierten sich auf die Frage, ob Algorithmen zwischen Kombattant\*innen und Zivilist\*innen unterscheiden oder das Erfordernis der Verhältnismäßigkeit erfüllen könnten, zwei wichtige Grundsätze des humanitären Völkerrechts (IHL), während sich die ethische Kritik vor allem auf die Menschenwürde konzentrierte. Diese enge Fokussierung auf ethische und rechtliche Fragen an einem bestimmten Punkt in der „Wirkungskette“ bedeutet jedoch, dass viele aktuelle militärische KI-Anwendungen sich einer genauen Prüfung weitgehend entziehen. Aus sicherheitspolitischer Sicht betonen kritische Argumente in der Regel die Bedenken der Rüstungskontrolle, insbesondere die Gefahren eines eskalierenden „Hyperkriegs“[^3] oder eines Krieges im Prozessortakt,[^4] der dem Ziel der traditionellen Rüstungskontrolle zuwiderläuft, Konflikte durch Maßnahmen wie Entflechtungszonen („disengagement zones“) oder die Verhinderung von Überraschungsangriffen zu verlangsamen. Der zunehmende Einsatz von KI und die Verdrängung des Menschen aus den Entscheidungsketten deuten auf eine gefährliche Beschleunigung hin, die über die engen Verwendungszwecke hinausgeht, die normalerweise Gegenstand der Debatte waren.

## Der extensive Einsatz militärischer KI

### Der Einsatz von militärischer KI innerhalb der „Wirkungskette“
Die „Wirkungskette“, englisch „Kill Chain“ oder auch „Targeting Cycle“, umreißt sechs grundlegende Schritte eines militärischen Einsatzes: Auffindung, Festlegung, Verfolgung, Zielzuweisung, Bekämpfung und Wirkungskontrolle. Die Phasen „Zielzuweisung“ und „Bekämpfung“ werden oft als „kritische Funktionen“ bezeichnet, da sie in direkte Kampfhandlungen eingebunden sind. KI-Software unterstützt inzwischen fast jeden Schritt.

<Aside>
KI-Software unterstützt inzwischen fast jeden Schritt der „Wirkungskette“.
</Aside>

Für die **Auffindung** potenzieller Ziele analysiert KI visuelle und Überwachungsdaten (z. B. Satellitenbilder, Drohnenaufnahmen, Daten von Mobilfunkgeräten) und verdichtet sie zu verwertbaren Informationen. Das Projekt Maven, das 2017 vom Pentagon initiiert wurde und im Januar 2023 unter Aufsicht der US National Geospatial Intelligence Agency (NGA) in Betrieb genommen wurde nutzt KI, um Objekte zu identifizieren und zu klassifizieren und Muster wie z. B. Konvoiformationen zu erkennen.[^5] Zu ähnlichen Bemühungen gehören Israels Gospel für die gezielte Überwachung von Infrastrukturen und Lavender, das bislang unbestätigten investigativen Quellen menschliche Ziellisten aus Telekommunikations- oder anderen Daten erstellt.[^6]

In der **Erkennungs- und Verfolgungsphase** hilft die KI bei der Geolokalisierung potenzieller Ziele (z. B. mobiler Geräte). Drohnen können bewegliche Ziele autonom verfolgen und sogar Standorte vorhersagen, wenn keine Sichtverbindung besteht. Systeme wie das amerikanische Gorgon Stare[^7] und neuere WAMI (Wide-Area Motion Imagery) Anwendungen (z. B. BlackKite-I/RedKite-I von Logos Technology) können Gebiete von der Größe einer Stadt nahezu in Echtzeit überwachen und dabei Hunderte von Objekten verfolgen.[^8]

KI spielt zunehmend eine Rolle in der kritischen **Zielzuweisungs- oder Auswahlphase**. Indirekt hilft Software (z. B. das Blast Prediction Tool des US Army Corps of Engineers[^9]) bei der Optimierung von Waffeneinschlägen und Angriffsvektoren zur Minimierung von Kollateralschäden. Direkt helfen komplexe Algorithmen bei der konkreten Auswahl von Zielen. Verteidigungssysteme wie Aegis oder Phalanx der US-Marine können eingehende Bedrohungen klassifizieren und priorisieren. In Szenarien mit hoher Bedrohung können sie autonom Ziele auswählen und **bekämpfen**, ohne dass ein Mensch in Echtzeit eingreifen muss, womit sie nach US-Definition als „autonome Waffen“ zu bezeichnen sind.[^10] Ähnliche defensive Kurzstrecken-Luftabwehrsysteme (Short Range Air Defense, SHORAD) sind z. B. Skyranger von Rheinmetall, Pantsir-S1/S2/SM von Russland und SWS3 von China, die in der Regel auf nicht-menschliche Bedrohungen abzielen. Loitering Munition (manchmal auch als „Kamikaze-Drohnen“ beschrieben), wie die israelischen Harpy oder Harop können autonom kreisen, bis sie Ziele entdecken. Während die ältere Harpy keine menschlichen Bediener\*innen benötigt, um einen Angriff zu bestätigen, ist die modernere Harop auf menschliche Autorisierung für den Einsatz angewiesen. Für die Zukunft wird immer umfangreichere autonome Zielauswahl bei Loitering Munition erwartet. Firmen wie der deutsche Rüstungsanbieter Helsing experimentieren mit KI-gestützter Erkennung für Systeme, z. B. ihre HX-2.[^11]

Und schließlich unterstützt die KI die Gefechtsschadenermittlung (Battle Damage Assessment, BDA) und die Kampfbewertung (Combat Assessment, CA). Die KI vergleicht Vorher-Nachher-Bilder, klassifiziert Schäden und fusioniert Sensordaten, was die technischen Herausforderungen der anfänglichen Zielidentifizierung widerspiegelt. Viele moderne Militärs werden wahrscheinlich bald KI in der BDA einsetzen. Die Bundeswehr hat zum Beispiel eine Konzeptstudie über teilautomatisierte BDA-Prozesse bis September 2024 in Auftrag gegeben.[^12]

Entscheidend ist, dass wir die Integration mehrerer – auch kritischer – Schritte der Wirkungskette in einzelne KI-Systeme sehen. Zu den ersten Beispielen gehört das „AlphaDogfights Trial“ der <Term t="darpa">DARPA</Term> im August 2020, bei dem die KI einen menschlichen Piloten in einem simulierten Luftkampf dominierte.[^13] Im Jahr 2023 haben die USA echte Kampfjet-Tests mit KI durchgeführt.[^14] Und während Details noch spärlich sind, tauchten im Jahr 2021 Berichte über chinesische KI-Simulationen auf, in denen KI-Agenten menschliche Pilot\*innen besiegten.[^15] Diese Entwicklung ist nicht nur auf Groß- und Supermächte beschränkt – 2025 verkündete Helsing, dass zusammen mit Saab ebenfalls die autonome Kampfsteuerung eines Kampfjets gelungen sei.[^16] Dieser Trend unterstreicht die zunehmende Einbeziehung von KI in den gesamten Zyklus der Wirkungskette, von der Suche und Verfolgung bis hin zur Auswahl des Ziels, der Einsatzentscheidung, dem Einsatz und der Auswertung nach dem Angriff.

### Der breitere Einsatz von militärischer KI außerhalb der „Wirkungskette“
Aber auch für den Einsatz von KI beim Militär außerhalb des Wirkungsketten-Zyklus gibt es zahlreiche Beispiele, darunter der Einsatz von KI bei der Entscheidungsfindung für Atomwaffen. Das Folgende ist nur ein begrenzter Überblick über verschiedene Themen, die sich immer weiter von der Wirkungskette im konventionellen Bereich entfernen.

<Aside>
Auch außerhalb der „Wirkungskette“ findet KI breiten Einsatz, z. B. in Ausbildung, Missionsplanung und Logistik.
</Aside>

**Missionsplanung und -vorbereitung:** Wenn es um die Planung von Einsätzen geht, unterstützen moderne KI-Systeme die Planenden, indem sie riesige Datenmengen aus verschiedenen Quellen zusammenführen und schnell einsetzen, um die „Zusammenführung von Erkenntnissen und die Ausrichtung von Zielen, das Bewusstsein für das Kampfgebiet und die Planung zu verbessern und die Entscheidungsfindung zu beschleunigen“, wie eine Pressemitteilung der NATO im Zusammenhang mit der Implementierung von Palantirs Maven Smart System NATO (MSS NATO) im Jahr 2025 beschreibt (unsere Übersetzung).[^17] Darüber hinaus sind einige Systeme, darunter auch MSS, in der Lage, Aspekte eines Militäreinsatzes zu simulieren, um Schwachstellen aufzudecken und Vorschläge für Routen oder mitzuführende Waffen und Ausrüstung zu unterbreiten. Angesichts der Fähigkeit der KI, unerwartete Lösungen für bekannte Aufgaben zu finden (wie 2016, als eine KI den Go-Großmeister Lee Sedol mit einem völlig unerwarteten Vorgehen besiegte), liegt es auf der Hand, dass die Simulation von Millionen potenzieller Szenarien die Missionsplanung in eine bisher unbekannte Dimension führen wird.[^18] Das deutsche „GhostPlay“ (https://www.ghostplay.ai/), ein „virtueller Zwilling“ der militärischen Realität, ist ein weiteres Beispiel dafür.

**Ausbildung:** Ein neuerer Aspekt der Debatte ist die Frage, wie KI eingesetzt werden kann, um die Ausbildung von Soldat\*innen zu optimieren, sowohl auf der Ebene von Einheiten als auch auf individueller Ebene. Es liegt auf der Hand, dass eine KI neue Trainingsszenarien generieren kann, die auf den Leistungen des Einzelnen oder der Einheit in früheren Übungen basieren, um sich auf erkannte Schwächen zu konzentrieren.[^20] Auf einer breiteren Ebene kann die KI Wargaming-Szenarien für Manöver oder großangelegte Übungen erstellen. Einige Systeme werden bereits für eine breitere Anwendung getestet, z. B. das Pilot Training Next (PTN) Programm der U.S. Air Force für einzelne Soldat\*innen oder das Fleet Synthetic Training (FST) Programm der U.S. Navy,[^20] das KI nutzt, um komplexe Szenarien der Seekriegsführung für ganze Flotten zu simulieren.[^21]

**Logistik:** Wenn wir den berühmten Ausspruch von John J. Pershing „Infanterie gewinnt Schlachten, Logistik gewinnt Kriege“ und Clausewitzʼ Betonung der Konzentration von Kräften in Zeit und Raum bedenken, ist es keine Überraschung, dass KI auch in der militärischen Logistik eine besondere Rolle spielt. Neben der (doppelten) Nutzung von zivilen COTS (Commercial Off-The-Shelf)-Anwendungen, bei denen auch die Optimierung der Logistik eine entscheidende Rolle spielt, ist auch das Militär aktiv an der Entwicklung und Anpassung von KI-Lösungen beteiligt, die speziell auf die besonderen logistischen Herausforderungen zugeschnitten sind. Dazu gehören die Logistik in umkämpften Umgebungen und unter schwierigen Bedingungen sowie der Umgang mit klassifiziertem und/oder gefährlichem Material. KI kann zum Beispiel dabei helfen, Lieferketten genau zu überwachen, um potenzielle Engpässe vorherzusagen und frühzeitig zu beheben, oder Wartungsabläufe auf der Grundlage der Vorhersage mechanischer Ausfälle zu verbessern, um nur einige Beispiele zu nennen. Infolgedessen hat die US Defense Logistics Agency (DLA) ab Juni 2024 ein KI-Kompetenzzentrum eingerichtet, und andere Streitkräfte folgen diesem Beispiel.[^22]

<Figure src="assets/AF_Prozesskategorien_DE.jpg" size="large" caption="Es gibt verschiedene Möglichkeiten, die Prozesse der AF zu kategorisieren. Die hier abgebildete Möglichkeit geht vom Zustand des Ausgangsmaterials bei der Herstellung der Schichten aus und ordnet dann die weiteren Prozesse nach dem Grundprinzip zur Herstellung der Schichten und des Materialzusammenhalts. Dies erlaubt eine übersichtliche Darstellung der Unterschiede der laut DIN EN ISO/ASTM 52900 bestimmten Prozesskategorien." alt="Baumdiagramm zu den Prozesskategorien der Additiven Fertigung. Auf der obersten Ebene ist eine Box mit der Beschriftung ‘Additiver Fertigungsprozess’, von der drei Pfeile ausgehen zu Boxen mit den Beschriftungen ‘Flüssigbasiert’, ‘Feststoffbasiert’ und ‘Pulverbasiert’. Von ‘Flüssigbasiert’ gehen zwei Pfeile aus zu Boxen mit den Beschriftungen ‘Extrusion geschmolzenen Materials’ und ‘Lichtreaktives Polymeraushärten’. Von ‘Extrusion geschmolzenen Materials’ geht ein Pfeil aus auf eine Box mit der Beschriftung ‘Materialextrusion’. Darunter ist eine Illustration, die eine Düse zeigt, die Materialschichten übereinander aufträgt. Von ‘Lichtreaktives Polymeraushärten’ gehen zwei Pfeile auf Boxen: In einer steht ‘Badbasierte Photopolymerisation’, darunter eine Illustration von Schichten im Pulverbett mit einer Lichtquelle darüber. In der anderen steht ‘Freistrahl-Materialauftrag’, darunter eine Illustration von Materialschichten und darüber eine Flüssigkeitsquelle und eine Wärmequelle. Von ‘Feststoffbasiert’ auf der zweiten Ebene geht ein Pfeil auf eine Box mit der Beschriftung ‘Verschmelzung gestapelter Folien’. Von dort aus wiederum zeigt ein Pfeil auf eine Box mit der Beschriftung ‘Schichtlaminierung’, darunter steht eine Illustration von Materialschichten im Pulverbett mit einer Flüssigkeitsquelle und einer scharfen Spitze, die sich auf das Material zubewegt. Von ‘Pulverbasiert’ auf der zweiten Ebene gehen zwei Pfeile auf Boxen, die jeweils mit ‘Selektives Verschmelzen’ und ‘Reaktives Aushärten’ beschriftet sind. Von ‘Selektives Verschmelzen’ gehen zwei Pfeile aus. Der eine zeigt auf eine Box mit der Beschriftung ‘Pulverbettbasiertes Schmelzen’ und einer Illustration von Materialschichten im Pulverbett mit einem auf die Oberfläche gerichteten Laserstrahl. Der andere Pfeil zeigt auf eine Box mit der Beschriftung ‘Materialauftrag m. gerichteter Energieeinbringung’ und eine Illustration von Materialschichten mit einem auf die Oberfläche gerichteten Laserstrahl und einem Rohr, das Pulver aufträgt. Von ‘Reaktives Aushärten’ auf der dritten Ebene geht ein Pfeil auf eine Box, in der steht ‘Freistrahl-Bindemittel-Auftrag’, darunter eine Illustration von Materialschichten im Pulverbett mit einer Flüssigkeitsquelle darüber."/>

## Beurteilung und Schlussfolgerung

Auch wenn sich die Beispiele fast ausschließlich auf westliche Länder, insbesondere die USA, beschränken, wäre es falsch anzunehmen, dass andere, weniger transparente Länder nicht in die militärische Nutzung von KI investieren, um von deren Vorteilen zu profitieren. Die Tatsache, dass viele Anwendungen nicht in den Bereich der kritischen Funktionen der Wirkungskette fallen, hat im Schatten der jüngsten internationalen Debatten über LAWS zu einer enormen Entwicklung geführt. Diese Frage ist ebenfalls problematisch, aber wahrscheinlich noch schwieriger einzuschränken. In allen diskutierten Bereichen ist es das erklärte Ziel, die Effizienz der vorhandenen Machtmittel zu verbessern und vor allem die Prozesse zu beschleunigen, um auf dem Schlachtfeld einen Vorteil zu erlangen, selbst wenn eine Form menschlicher Kontrolle eingesetzt wird.

Unter dem Gesichtspunkt des der Rüstungskontrolle innewohnenden Stabilitätskonzepts ist die militärische Nutzung von KI per se problematisch: Erstens werden Gleichgewichte schwieriger zu bewerten und zu kalkulieren, wenn ein KI-gestütztes System von Systemen ins Spiel kommt, wodurch ältere oder scheinbar minderwertige Systeme aufgewertet und wieder relevant werden. Zweitens verkürzt die Beschleunigung der Kriegsführung die Zeit sowohl für die Warnung als auch für die Beurteilung, ob ein Angriff unmittelbar bevorsteht oder bereits im Gange ist, was zu höheren Alarmstufen und unangemessenen oder falschen Reaktionen aufgrund des Zeitdrucks führen kann. Die Idee, die Rüstungskontrolle auf scheinbar harmlose oder unproblematische Bereiche wie die Logistik auszuweiten, ist nicht neu. Das Mitte der 2010er Jahre in Deutschland entwickelte Konzept der „verifizierten Transparenz“ verwendet als explizites Beispiel eine optimierte Logistik, bei der es gilt, der Angst vor Entwertung von Rückzugsgebieten und einem Überraschungsangriff mit rüstungskontrollpolitischen Instrumenten zu begegnen.[^23]

<Aside>
Aus Sicht des Stabilitätskonzepts ist die militärische Nutzung von KI per se problematisch.
</Aside>

Leider müssen wir ehrlich sagen: Die Zeiten erlauben keine konkreten – geschweige denn rechtsverbindlichen – Rüstungskontrollmaßnahmen, die nicht im klaren nationalen Interesse der wichtigsten internationalen Akteure liegen. Wie wir in der Debatte über LAWS gesehen haben, werden ethische und rechtliche Argumente nicht unbedingt diejenigen Akteure überzeugen, die in der Entwicklung und Beschaffung von KI-gestützten Waffensystemen einen klaren militärischen Vorteil sehen.

Interessanterweise begann im Jahr 2023 eine neue Debatte, die von den Niederlanden angestoßen wurde. Dort fand das erste Gipfeltreffen über verantwortungsvolle künstliche Intelligenz im militärischen Bereich (Summit on Responsible Artificial Intelligence in the Military, oft als <Term t="reaim">REAIM</Term> bezeichnet) statt, das sich mit der „verantwortungsvollen“ Entwicklung, dem Einsatz und der Nutzung von KI beim Militär beschäftigt. 60 Staaten einigten sich auf einen unverbindlichen „Aufruf zum Handeln“,[^24] in dem die Auswirkungen von KI auf die internationale Sicherheit und Stabilität ausdrücklich erwähnt werden. Angesichts der rasanten Entwicklung der KI im zivilen Bereich, die auch auf den militärischen Bereich übergreift, betont REAIM auch den Multi-Stakeholder-Ansatz. Dies ist zwar ein guter Anfang, aber der Schwerpunkt liegt immer noch auf nationalen Strategien und nationaler Verantwortung, ohne dass die Folgen des interaktiven Einsatzes militärischer KI und seine Auswirkungen auf die internationale Stabilität, sowohl in Krisen als auch auf die strategische konventionelle Stabilität, angesprochen werden. Es ist zwar hilfreich, das Bewusstsein der Staaten für die Gefahren unausgereifter KI und den damit verbundenen Verlust menschlicher Kontrolle zu schärfen, aber dies geht nicht auf die Gefahren ein, die von KI ausgehen, die die Kriterien der „Zuverlässigkeit“ und „Vertrauenswürdigkeit“ erfüllt. Wie schon während des Kalten Krieges ist es wichtig, die Wechselwirkungen hervorzuheben, die sich aus einzelnen Rüstungsentscheidungen ergeben.

<Aside>
Es ist wichtig, die Wechselwirkungen hervorzuheben, die sich aus einzelnen Rüstungsentscheidungen ergebe.
</Aside>

Es ist daher wichtig, die Auswirkungen der breiten militärischen Nutzung von KI auf die künftige Kriegsführung und die Art und Weise, wie sich die Interaktionen zwischen Maschinen und Geschwindigkeit auf die Stabilität und Eskalation auswirken, direkt anzusprechen. Es scheint nicht der Fall zu sein, dass die globalen Agierende die schwierigen sicherheitspolitischen Fragen im Zusammenhang mit dem breiten Einsatz von KI in fast allen militärischen Kontexten tatsächlich erkannt haben, und es scheint auch nicht so, als würden sie mit einer interessengeleiteten Rüstungskontrollpolitik darauf reagieren. Der Aufruf zum Handeln fordert Universitäten und Denkfabriken ausdrücklich dazu auf, „zusätzliche Forschung zu betreiben, um die Auswirkungen, Chancen und Herausforderungen einer schnellen Einführung von KI im militärischen Bereich besser zu verstehen“ – eine Aufgabe, die eine kritische Perspektive erfordert.

<Aside>
Debatten um KI im Militär sollten die breite militärische Nutzung von KI und ihre Auswirkungen mit einschließen.
</Aside>

[^1]: Z. B. Rosert, E., & Sauer, F. (2020). How (not) to stop the killer robots: A comparative analysis of humanitarian disarmament campaign strategies. Contemporary Security Policy, 42(1), 4-29. https://doi.org/10.1080/13523260.2020.1771508
[^2]: Z. B. Altmann, J., & Sauer, F. (2017). Autonomous Weapon Systems and Strategic Stability. Survival, (59)5, 117-142. Alwardt, C., & Schörnig, N. (2022). A necessary step back? Recovering the security perspective in the debate on lethal autonomy. Zeitschrift für Friedens- und Konfliktforschung (Journal for Peace and Conflict Studies), 10, 295–317. https://doi.org/10.1007/s42597-021-00067-z
[^3]: Allen, J.R., & Husain, A. (2017). On Hyperwar. Proceedings, 143(7), https://www.usni.org/magazines/proceedings/2017/july/hyperwar
[^4]: Z. B. Amt für Heeresentwicklung der Bundeswehr. (2019). Künstliche Intelligenz in den Landstreitkräften. https://www.bundeswehr.de/resource/blob/156024/d6ac452e72f77f3cc071184ae34dbf0e/download-positionspapier-deutsche-version-data.pdf
[^5]: National Geospatial-Intelligence Agency. (n.d.). GEOINT Artificial Intelligence. United States government. Abgerufen am 9. September 2025, unter https://www.nga.mil/news/GEOINT_Artificial_Intelligence_.html
[^6]: Abraham, Y. (2024, 3. April). ‘Lavender’: The AI machine directing Israel’s bombing spree in Gaza. +972 Magazine. https://www.972mag.com/lavender-ai-israeli-army-gaza/
[^7]: Trimble, S. (2014, 2. Juli). Sierra Nevada fields ARGUS-IS upgrade to Gorgon Stare pod. Flight Global. https://www.flightglobal.com/civil-uavs/sierra-nevada-fields-argus-is-upgrade-to-gorgon-stare-pod/113676.article
[^8]: Logos Technologies. (n.d.). Redkite-I. Abgerufen am 8. September 2025, unter https://www.logostech.net/products/redkite-i/; Logos Technologies. (n.d.). Blackkite-I. Abgerufen am 8. September 2025, unter https://www.logostech.net/products/blackkite-i/
[^9]: US Army Corps of Engineers. (n.d.). PDC Software. United States government. Abgerufen am 9. September 2025, unter https://www.nwo.usace.army.mil/About/Centers-of-Expertise/Protective-Design-Center/PDC-Software/
[^10]:United States of America. (2023). DoD Autonomy in Weapon Systems (DoD Directive 3000.09). United States Department of Defense. https://www.esd.whs.mil/portals/54/documents/dd/issuances/dodd/300009p.pdf
[^11]: Helsing. (n.d.). HX-2 – AI Strike Drohne. Abgerufen am 8. September 2025, unter https://helsing.ai/de/hx-2
[^12]: OHB SE. (2024, 11. September). OHB Digital Connect deepens AI and image processing expertise in concept study for the German Armed Forces. https://www.ohb.de/en/news/ohb-digital-connect-deepens-ai-and-image-processing-expertise-inconcept-study-for-the-german-armed-forces
[^13]: Defense Advanced Research Projects Agency. (2020, 26. August). AlphaDogfight Trials Foreshadow Future of Human-Machine Symbiosis. United States Department of Defense. https://www.darpa.mil/news/2020/alphadogfight-trial
[^14]: Decker, A. (2024, 19. April). An AI took on a human pilot in a DARPA-sponsored dogfight. Defense One. https://www.defenseone.com/technology/2024/04/man-vs-machine-ai-agents-take-human-pilot-dogfight/395930/
[^15]: Pickrell, R. (2021, 15. Juni). China says its fighter pilots are battling artificial-intelligence aircraft in simulated dogfights, and humans aren’t the only ones learning. Business Insider. https://www.businessinsider.com/china-pits-fighter-pilots-against-ai-aircraft-in-simulated-dogfights-2021-6
[^16]: Wang, A. (2025, 17. Juni). Taiwan seals Ukraine combat-tested drone software deal to help deter China. Reuters. https://www.reuters.com/business/aerospace-defense/taiwan-seals-ukraine-combat-tested-drone-software-deal-help-deter-china-2025-06-17/
[^17]: North Atlantic Treaty Organization. (2025, 14. April). NATO acquires AI-enabled warfighting system. North Atlantic Treaty Organization. https://shape.nato.int/news-releases/nato-acquires-aienabled-warfighting-system
[^18]: Jung, H. (2024). A Glimpse into the Future Battlefield with AI-Embedded Wargames. Proceedings, 150(6). https://www.usni.org/magazines/proceedings/2024/june/glimpse-future-battlefield-ai-embedded-wargames
[^19]: Iankersey3. (2024, 20. Juni). 495. Training Transformed: AI and the Future Soldier. Mad Scientist Laboratory. https://madsciblog.tradoc.army.mil/495-training-transformed-ai-and-the-future-soldier/; Jung, H. (2024)
[^20]: RINA. (n.d.). AI-powered Aviation scenarios. Abgerufen am 8. September 2025, unter https://www.rina.org/en/media/CaseStudies/ai-powered-aviation-scenarios
[^21]: Homewood-waszkiewicz, C. (2024, 17. April). The Evolution and Crucial Role of Specialised Industrial Computing Enhancing Naval Defence Innovations. Captec. https://www.captec-group.com/evolution-of-industrial-naval-computing/
[^22]: Reece, B. (2025, 13. März). DLA applying AU to supply chain risk management, warfighter readiness. Defense Logistics Agency, United States government. https://www.dla.mil/About-DLA/News/News-Article-View/Article/4117309/dla-applying-ai-to-supply-chain-risk-management-warfighter-readiness/
[^23]: Schmidt, H.-J. (2013). Verified Transparency. New conceptual ideas for conventional arms control in Europe. (PRIF Report No. 119). Peace Research Institute Frankfurt. https://www.prif.org/publikationen/publikationssuche/publikation/verified-transparency
[^24]: Ministry of Foreign Affairs, & Ministry of Defence. (2023). REAIM 2023 Call to Action. Government of the Netherlands. https://www.government.nl/documents/publications/2023/02/16/reaim-2023-call-to-action
