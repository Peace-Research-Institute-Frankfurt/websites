---
title: Red Teaming (im KI-Kontext)
term_id: red-teaming
---

ein interaktives Verfahren zum Testen von KI-Modellen, das sch√§dliches Verhalten wie die Preisgabe sensibler Daten und die Erzeugung toxischer, voreingenommener oder sachlich falscher Inhalte verhindern soll.
