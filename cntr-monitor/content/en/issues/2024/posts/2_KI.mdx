---
order: 1
eyebrow: Artifical Intelligence
title: Artificial Intelligence, Semiconductors, and the Military
intro: 'The development of processes in the field of artificial intelligence (AI) has burgeoned  in recent years, driven in particular by global tech companies and research institutions. At the same time, the application of this dual-use technology in battlefield control and data analysis in Ukraine or for the large-scale selection of relevant military targets in Gaza demonstrates the growing importance of this technology for military actors. However, these applications also illustrate the challenges of this technology in terms of the limits of human control and the comprehensibility of automated decisions and underline the need for regulation. At the same time, the dominance of AI and semiconductor technologies and the availability of the underlying production chains is increasingly developing into a global power play.'
category: Trends
tags:
  - AI
  - Artificial Intelligence
  - Halbleiter
  - 5G
authors:
  - t-reinhold
---

<Leadin>Even though <Term t="AI-ML">artificial intelligence</Term></Leadin> and its subfield <Term t="AI-ML">machine learning (ML)</Term> covers a wide variety of approaches, current AI systems are almost exclusively based on the concept of what are known as artificial neural networks (ANN). This approach, which is based on ideas from the 1940s, simulates the function and networking of human brain cells. Although already extensively researched in the 1980s and 1990s, it is only today’s semiconductor technologies and the production of highly powerful, inexpensive, and small chips that have achieved the kind of performance that, in conjunction with more efficient software architectures, can enable modern AI applications. Although approaches such as <Term t="symbolische-ki">symbolic AI</Term>, <Term t="entscheidungsbaeume">decision trees</Term>, and <Term t="ev_algorithmus">evolutionary algorithms</Term>  do play a role in specific applications, in public debate, the term AI generally refers to ANN.

<Aside title="LLM, LMM und AGI">AI models can be differentiated according to their capabilities and the type of training data, see <Term t="llm-lmm-agi">LLM, LMM, and AGI.</Term> </Aside>

The key element of an AI application is the <Term t="ki-modell">“model,”</Term> a data structure for storing digital information. This is developed in a <Term t="daten-training">“training process”</Term> using extensive data that is tailored to the desired problem-solving capability. The process in question is usually deep learning (DL). Here, models are either tailored to a specific task or pretrained in the form of foundation models, often marketed commercially, which are then optimized for the actual application context in further training processes using specific data. The quality and availability of training data is crucial when it comes to the achievable problem-solving ability of AI applications , which is why the data is often compiled by specialized companies, curated by hand, and sold on the market as an economic commodity. Current AI generations differ in terms of the kind of data  that can be processed in training, during application, and for user interactions. While this distinction is increasingly becoming blurred, the world’s leading AI companies, like OpenAI, Meta, Microsoft or Anthropic, are working on what has been dubbed “artificial general intelligence” (AGI). The aim is for AGI to possess human-like cognitive abilities and thus be able to learn from experience, draw conclusions independently, and interact with other AI systems. When and whether this ambitious goal can be achieved, however, is disputed among experts.[^1]

<Figure src="assets/KNN_EN.jpg" size="large" caption="The interactions of neuronal cells are recreated in the form of ANNs (simplified representation)." alt="Schematic illustration of an artificial neural network: An image of a map represents training information in the form of text, images or videos. The map is broken down into small parts, with arrows leading from these parts to nodes, which in turn are linked to other nodes in other layers. The picture shows that there are many more layers in between. At the end, the connections lead to two nodes, from one an arrow leads to the text Output A, from the other an arrow leads to the text Output B."/>

All these AI systems need enormous computational power to be trained and executed in a finished application. In contrast to cloud server centers, this is only possible with much more powerful chips that can be operated at full load and for longer periods of time. The newest generation of AI accelerators (the “GB200 architecture”) by market leader Nvidia, which combines an AI chip (<Term t="gpu">GPU</Term>) with other necessary hardware, for instance has a power consumption of around 1,500 watts per unit with a continuous computing power of 45*10¹² operations per second.[^2] For comparison, an iPhone 14 manages approximately 1.4*10¹² operations per second in short load peaks.[^3] Artificial intelligence data centers, in which tens to hundreds of thousands of these devices are operated together, achieve a total power consumption of 100 megawatts and more.[^4] Since such server systems have to be equipped with the network infrastructures needed for internal data exchange as well as for the power supply and the enormously complex cooling of the systems, the production of these technical systems, their construction, and operation are extremely expensive.[^5]

## Military Applications of AI

The use of AI in Ukraine’s fight against Russia or in Israel’s war against Hamas has highlighted the dynamics of introducing new technologies  with dual-use potential into military applications. In the first case, AI applications have emerged out of the situation and are embedded ad hoc into military processes and de facto tested, adapted, and expanded “in the field.” The example of Israel, on the other hand, illustrates the long-term strategic embedding of such applications into military decision-making processes, combined with the development of the necessary logistical and technical structures. What the two wars have in common, however, is that AI systems are predominantly used as a tool in tactical planning to support and accelerate decision-making through the automated aggregation and evaluation of a wide variety of data sources—what is referred to as “decision support” or “battlefield management systems.” While in Ukraine, these systems are used to predict troop movements, the Israeli systems “Lavender”[^6] and “Gospel”[^7] have become known in the course of the Gaza War and are used to identify physical objects as well as people and mark them as potentially relevant military targets. This application of AI can be seen as the step after the approach that has become known as big data, i.e., bringing together extensive data from modern military sensor technology, such as image and video data, as well as the movement profiles of targets, and processing them with technical support.[^8] This reduction in sensor-to-shooter time, which is understood as a tactical advantage from a military perspective,[^9] further increases the speed of warfare, while the role of human control and possibility of intervention are sidelined even more and the latter increasingly perceived as a bottleneck.[^10]

<Figure src="assets/191217-F-QF982-0089_web.jpg" size="large" caption="Soldiers use a tablet during an exercise demonstrating the capabilities of the AI-supported Advanced Battle Management System." alt="Several soldiers are looking at a tablet that one of them is holding." credit="Photo: U.S. Air Force photo by Tech. Sgt. Joshua J. Garcia."/>

The trend towards the autonomization of military weapon systems is also fueling the development and use of AI. On the one hand, such systems are supposed to be able to operate in unknown territory or under variable conditions and require the ability to react flexibly to situations rather than adhere to rigid instructions. Artificial intelligence systems provide these capabilities, which can for instance involve operating autonomously in a target area while taking obstacles into account or identifying military targets, even with noisy data sources. On the other hand, AI systems are capable of capturing patterns or deriving rules from data autonomously during the training process. This makes it possible for AI systems to learn highly complex skills, such as the control and aerial combat of fighter jets,[^11] without those skills needing to be explicitly formulated. In terms of technology, the fact that different AI systems can also be operated in a coupled manner comes into play here. For example, the evaluation of radar data, the identification of potential targets, or the navigation of a vehicle can be achieved by individual AI systems, and their outputs can then be combined in a comprehensive AI system for overall control.

In addition to these complex AI applications, some special capabilities are now so technologically advanced—such as image evaluation or speech analysis, which are now built into chips in every modern smartphone—that even small military devices such as quadrocopters can be equipped with them at a low cost, on a mass scale, and improved accordingly. This broad rollout enables applications such as those to be implemented in the US “Replicator” program,[^12] which envisages the large-scale, automated and autonomous deployment of swarms of drones—an idea that has recently also been discussed within NATO in the context of border security against Russia.[^13]

Artificial intelligence is also playing an increasingly important role in cyberspace, for example, in the automated analysis of data transfers to identify unusual activities indicating cyberattacks, to detect malware, or to automatically trigger countermeasures.[^14] At the same time, AI can also be used to automatically generate new malware based on available databases of security vulnerabilities or to tailor it for selected targets.[^15]

<Aside>Für eine Diskussion dieses Aspekts, siehe den [Beitrag von Kadri Reis](/2024/auswirkungen-von-technologischem-fortschritt-auf-die-biosicherheit/).</Aside>

Diese Fähigkeit von KI, neue Varianten eines digitalisierten Datensatzes auf Grundlage bestehender Informationen zu generieren, wird mit Blick auf die Herstellung neuer Bio- und Chemiewaffen als hochkritisch angesehen.

Hinsichtlich der Analyse von Bild- und Sensordaten wird KI immer wieder auch im Rahmen der nuklearen Abschreckung und der dafür notwendigen Überwachungs- und Sensorin­frastrukturen diskutiert. Da insbesondere für diesen Einsatz die Reaktionsgeschwindigkeit bei einem hypothetischen nuklearen Angriff als entscheidend betrachtet wird, sollen KI-Systeme hier für die Erkennung nuklearer Angriffsvorbereitungen und Aktivitäten eingesetzt werden.[^16] Gleichzeitig verdeutlicht dieses Szenario die Gefahr der „Eskalation aus Versehen“ und die Unabwägbarkeiten beim Einsatz einer schwer kontrollierbaren oder nachvollziehbaren Technologie, selbst wenn diese „nur“ zur Filterung und Analyse von Daten dient.

Zusammengefasst wird KI seitens militärischer Akteure als „Enabling“-Technologie aufgefasst, die bestehende Anwendungen optimiert oder die operative Ausweitung in bestimmten Einsatzszenarien ermöglicht. Eine wesentliche Motivation besteht dabei darin, taktische Vorteile durch die Beschleunigung von Entscheidungsprozessen sowie Informationsvorteile zu erlangen. In Verbindung mit autonomen Waffensystemen spielen darüber hinaus auch Überlegungen eine Rolle, die Gefahr eigener menschlicher Verluste durch den Einsatz technischer Geräte zu verringern. KI wird darüber hinaus als Lösung angesehen für ein immanentes Problem der zunehmenden Technisierung der Streitkräfte, nämlich dass immer bessere Waffen- und Sensortechnik in aller Regel auch immer größere Datenmengen erzeugen, die kaum mehr durch menschliche Operateure handhabbar sind.

<Callout>

Zusammengefasst wird KI seitens militärischer Akteure als „Enabling“-Technologie aufgefasst, die bestehende Anwendungen optimiert oder die operative Ausweitung in bestimmten Einsatzszenarien ermöglicht.

</Callout>

<Quote>

Zusammengefasst wird KI seitens militärischer Akteure als „Enabling“-Technologie aufgefasst, die bestehende Anwendungen optimiert oder die operative Ausweitung in bestimmten Einsatzszenarien ermöglicht.

</Quote>

## Ausblick und Empfehlungen

Angesichts des rasanten Fortschritts von KI-Technologie debattieren Staaten gegenwärtig in unterschiedlichen Formaten und oft in enger Kooperation mit Vertreter*innen der KI-Tech-Unternehmen, wie ein verantwortungsvoller Umgang mit KI aussehen kann und welche Form der Regulation dafür notwendig wäre.[^17] Insbesondere für die militärische Anwendung sollten sich diese Debatten dabei unmittelbar an den Fragen orientieren, wie sie bereits im Kontext autonomer Waffensysteme seit langem gestellt werden, etwa nach den Möglichkeiten menschlicher Kontrolle und Verantwortlichkeit sowie Vereinbarkeit solcher Systeme mit dem Völkerrecht, aber auch nach Gefahren für die militärische Stabilität zwischen möglichen Gegnern. Gleichzeitig darf dabei nicht außer Acht gelassen werden, dass selbst bei einer KI-gestützten Anwendung, deren finale Entscheidung durch einen menschlichen Operator getroffen wird, die KI selbst durch Filter- und Analyseprozesse unzählige Mikro-Entscheidungen getroffen hat, die weder im Trainingsprozess explizit und nachvollziehbar definiert worden sind noch dem Operator in der Situation der Entscheidung transparent sind.[^18] Auch wenn erste Ansätze der sogenannten „Erklärbaren KI“ (Explainable Artificial Intelligence – XAI)[^19] versuchen, diesen Black-Box-Charakter einer KI aufzulösen, so reichen diese bei weitem nicht an die benötigte Erklärbarkeit heran, wie sie menschliche Schlussfolgerungsprozesse bieten. Darüber hinaus führen diese Ansätze in aller Regel zu einer Reduktion der Leistungsfähigkeit und Reaktionsgeschwindigkeit einer KI, also den Hauptvorteilen dieser Technologie, und werden sich ohne verbindliche rechtliche Vorgaben kaum durchsetzen können.

Erste staatliche Vorstöße bei der Regulierung militärischer KI lassen aber auch Divergenzen hervortreten, insbesondere zwischen Staaten, die Teil der extrem zentralisierten KI-Produktionsketten sind, wie die USA, UK, die Niederlande und Taiwan, und Staaten, die daran aktuell nicht partizipieren, allen voran China. Angesichts der starken Zentralisierung und der globalen Abhängigkeit von Halbleiterfertigungsbetrieben in Taiwan wie TSMC (sogenannte Foundries) verstärkt diese Entwicklung allerdings auch die Sorge vor zunehmenden internationalen Spannungen. Dies wird in besonderem Maße in Form der „Chip Wars“ deutlich, mit denen die USA einerseits versuchen, chinesische Hersteller vom Zugriff auf spezialisierte KI-Chips und das dafür benötigte Know-how, die Herstellungsgeräte, Materialien und Produktionsketten abzuhalten[^20] und andererseits durch spezielle Mechanismen wie Kill-Switches in Chip-Herstellungsanlagen[^21] – die im Bedarfsfall die Geräte zerstören würden – ihren Verbündeten Taiwan vor dem chinesischen Hoheitsanspruch zu schützen.

Unabhängig von der individuellen Bewertung dieser Maßnahmen demonstrieren die USA aber auch, dass es durchaus Ansatzmöglichkeiten für die Regulierung von KI-Systemen gibt. So definiert die „Executive Order on Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence“ (Executive Order 14110 von 2023) technisch messbare Parameter, wie die für das Training oder die Ausführung eines KI-System benötigte Gesamtrechenleistung, als Grundlage für die US-Exportkontrolle solcher Geräte und fertiger KI-Produkte. Angesichts dieser Ansatzpunkte, verbunden mit dem Aspekt, dass es trotz des digitalen Charakters von KI-Anwendungen vor allem die spezialisierten Server- und Netzwerkgeräte sind, die leistungsfähige KI-Systeme ermöglichen, bestehen für die Rüstungskontrolle vielleicht noch Chancen. Dafür müssten auch andere Staaten diese Impulse aufgreifen, weiterentwickeln und unterstützen.

[^1]: Fjelland, R. (2020). Why general artificial intelligence will not be realized. Humanities and Social Sciences Communications,  7(1), 10. https://doi.org/10.1057/s41599-020-0494-4
[^2]: Spille, C. (2024, 18. März). Blackwell: Nvidia enthüllt seine nächste KI-Beschleuniger-Generation. heise online. https://www.heise.de/news/Nvidias-neue-KI-Chips-Blackwell-GB200-und-schnelles-NVLink-9658475.html
[^3]: Owen, M. (2022, 26. September). How iPhone speeds have grown in the last 5 years. appleinsider. https://appleinsider.com/articles/22/09/26/how-iphone-speeds-have-grown-in-the-last-5-years
[^4]: Patel, D., & Nishball, D. (2024, 17. Juni). 100k H100 Clusters: Power, Network Topology, Ethernet vs InfiniBand, Reliability, Failures, Checkpointing. SemiAnalysis. https://www.semianalysis.com/p/100000-h100-clusters-power-network
[^5]: Patel & Nishball, 2024.
[^6]: Abraham, Y. (2024, 3. April). ‘Lavender’: The AI machine directing Israel’s bombing spree in Gaza. 972 Magazine. https://www.972mag.com/lavender-ai-israeli-army-gaza/
[^7]: Davies, H., McKernan, B., & Sabbagh, D. (2023, 1. Dezember). ‘The Gospel’: How Israel uses AI to select bombing targets in Gaza. The Guardian. https://www.theguardian.com/world/2023/dec/01/the-gospel-how-israel-uses-ai-to-select-bombing-targets
[^8]: RAFAEL Advanced Defense Systems LTD. (2019). FIRE WEAVER - Tactical Networked Sensor-to-Shooter System. https://www.rafael.co.il/system/fireweaver/
[^9]: Skove, S. (2024, 7. März). Targeting time shrinks from minutes to seconds in Army experiment. DefenseOne. https://www.defenseone.com/threats/2024/03/targeting-time-shrinks-minutes-seconds-army-experiment/394758/
[^10]: Deutscher Ethikrat. (2023). Mensch und Maschine – Herausforderungen durch Künstliche Intelligenz—Stellungnahme des Deutschen Ethikrates. https://www.ethikrat.org/fileadmin/Publikationen/Stellungnahmen/deutsch/stellungnahme-mensch-und-maschine.pdf
[^11]: Copp, T. (2024, 5. April). An AI-controlled fighter jet took the Air Force leader for a historic ride. What that means for war. Politico. https://www.politico.com/news/2024/05/04/an-ai-controlled-fighter-jet-took-the-air-force-leader-for-a-historic-ride-what-that-means-for-war-00156147
[^12]: Katz, J. (2024, 20. Januar). Replicator’s ‘PRIME’ time: DIU seeks small USV interceptors ready for rapid production. Breaking Defense. https://breakingdefense.com/2024/01/replicators-prime-time-diu-seeks-small-usv-interceptors-ready-for-rapid-production/
[^13]: Milne, R. (2024). Six Nato countries plan ‘drone wall’ to defend borders with Russia. Financial Times. https://www.ft.com/content/949db465-cd27-4c66-9908-c2faa80b602b
[^14]: Jun, J. (2024, 30. April). How Will AI Change Cyber Operations?. War on the Rocks. https://warontherocks.com/2024/04/how-will-ai-change-cyber-operations
[^15]: Fang, R., Bindu, R., Gupta, A., Zhan, Q., & Kang, D. (2024, 2. Juni). Teams of LLM Agents can Exploit Zero-Day Vulnerabilities (arXiv:2406.01637). arXiv. http://arxiv.org/abs/2406.01637
[^16]: Topychkanov, P. (2019, Mai). The Impact of Artificial Intelligence on Strategic Stability and Nuclear Risk. In South Asian Perspectives (Band 1). SIPRI. https://www.sipri.org/publications/2019/research-reports/impact-artificial-intelligence-strategic-stability-and-nuclear-risk-volume-i-euro-atlantic
[^17]: Reinhold, T. (2024, 7. Mai). Der militärische Einsatz künstlicher Intelligenz braucht Regeln: Nur welche, darüber besteht keine Einigkeit. PRIF Blog. https://blog.prif.org/2024/05/07/der-militaerische-einsatz-kuenstlicher-intelligenz-braucht-regeln-nur-welche-darueber-besteht-keine-einigkeit
[^18]: Heaven, W. D. (2024, 4. März). Large language models can do jaw-dropping things. But nobody knows exactly why. MIT Technology Review. https://www.technologyreview.com/2024/03/04/1089403/large-language-models-amazing-but-nobody-knows-why/
[^19]: Barredo Arrieta, A., Díaz-Rodríguez, N., Del Ser, J., Bennetot, A., Tabik, S., Barbado, A., Garcia, S., Gil-Lopez, S., Molina, D., Benjamins, R., Chatila, R., & Herrera, F. (2020). Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information Fusion, 58, 82–115. https://doi.org/10.1016/j.inffus.2019.12.012
[^20]: Shepardson, D., & Nellis, S. (2024, 8. Mai). Intel, Qualcomm say exports to China blocked as Beijing objects. Reuters. https://www.reuters.com/technology/intel-flags-revenue-hit-us-revokes-certain-export-licenses-chinese-customer-2024-05-08
[^21]: Bloomberg. (2024, 22. Mai). ASML and TSMC can disable EUV machines. Taipei Times. https://www.taipeitimes.com/News/biz/archives/2024/05/22/2003818194
